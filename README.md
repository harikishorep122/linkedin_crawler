# Linkedin Crawler
Web Crawler to scrap profile data from Linkedin

About

The objective is to systematically visit one's connections linkedin profiles and extract data points from these pages. 
These extraced datapoints are then populated in a csv file and stored. This crawler is designed to be used for personal use. But it can be scaled up to pull large amounts of data.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Strategies

Every website has policies against bots and Linkedin has as well. This scrapper uses some ethical strategies to make sure that it does not load the server. Each request is sent after a significant cooldown period.  

Parsel is a BSD-licensed Python library to extract and remove data from HTML and XML using XPath and CSS selectors, optionally combined with regular expressions.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Technicalities

The scraper make use of libraries such as selenium, regular expressions, BeautifulSoup, parsel.
Selenium helps to automate the process of scrapping. The webdriver associated with selenium runs a headless browser in the background. 

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Conclusion
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Discalimer

## BIBLIOGRAPHY
